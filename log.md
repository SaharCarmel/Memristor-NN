# Meeting summaries and work log
### **Meeting #1:** *7/8/2019*
#### Meeting summary
#### Work log
#### Tasks
- [ ] Reference MNIST network
- [x] yaml config
- [x] data loading
- [ ] simulation logs
  - [ ] date
  - [ ] architecture
  - [ ] yaml file
  - [ ] time for convergence
  - [ ] hardware
  - [ ] plots
  - [ ] acuuracy
  - [ ] over fitting
#### Questions
- [ ] Should we implement multi-layer modules? If so, should we implement activation layers?
- [ ]  Optimizer: currently implemtned constant step gradient descent. pytorch has an optimizer module (with better optimization algortihms..)  but we wouldn't be able to use the manahtan rule.